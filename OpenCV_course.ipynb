{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c70920df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import cv2 as cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6467a6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'C:\\\\Lachin\\\\Data Science\\\\Data science\\\\Opencv\\\\'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4bce23a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread(path+'image1.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb370950",
   "metadata": {},
   "source": [
    "#### Image Reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "02d69739",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('image', image)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f48a394",
   "metadata": {},
   "source": [
    "#### Image Converting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "01980c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "imag_gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "cv2.imshow('Gray Image', imag_gray)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7d8e917",
   "metadata": {},
   "source": [
    "#### Image element accessing and changing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f8df058c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(636, 1024, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7af1e2a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image.item((356,1021,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5508b1c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "image.itemset((356,1021,2),255)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de707015",
   "metadata": {},
   "source": [
    "#### Different color channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0487b68e",
   "metadata": {},
   "outputs": [],
   "source": [
    "B, G, R = cv2.split(image)\n",
    "cv2.imshow('Orginal Image', image)\n",
    "cv2.imshow('Blue Image', B)\n",
    "cv2.imshow('Green Image', G)\n",
    "cv2.imshow('Red Image',R)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd007ecd",
   "metadata": {},
   "source": [
    "#### Image Merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "692b7b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "merge = cv2.merge([B+50,G+100,R+100])\n",
    "cv2.imshow('merge Image', merge)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d00cbbd",
   "metadata": {},
   "source": [
    "#### Image capturing through webcam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "967fb93e",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n"
     ]
    }
   ],
   "source": [
    "path1 = 'C:\\\\Lachin\\\\Data Science\\\\Data science\\\\Opencv\\\\my Images\\\\'\n",
    "img = cv2.VideoCapture(0)\n",
    "count=0\n",
    "\n",
    "while (True):\n",
    "    count+=1\n",
    "    check, frame = img.read()\n",
    "    cv2.imshow(\"my frame\", frame)\n",
    "    if cv2.waitKey(1000) ==ord(\"q\"):#waitkey is waiting for a key board argument\n",
    "        break\n",
    "    print(frame.shape)\n",
    "    cv2.imwrite(path1+f'img{count}.jpg', frame)\n",
    "img.release()\n",
    "cv2.destroyAllWindows()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45e0de11",
   "metadata": {},
   "source": [
    "#### Video Capturing through webcam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d7c5b4aa",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n"
     ]
    }
   ],
   "source": [
    "image = cv2.VideoCapture(0)\n",
    "fourcc_code = cv2.VideoWriter_fourcc(*\"WMV3\")\n",
    "video = cv2.VideoWriter(path1+'my_video.wmv',fourcc_code,10.0,(480,640))\n",
    "\n",
    "while (True):\n",
    "    check, frame = image.read()\n",
    "    video.write(frame)\n",
    "    cv2.imshow('my_image', frame)\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "    print(frame.shape)\n",
    "    cv2.imwrite(path1+'my_image.jpg', frame)\n",
    "video.release()\n",
    "image.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b767f8f",
   "metadata": {},
   "source": [
    "#### Draw Geometric Shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd9e1ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'C:\\\\Lachin\\\\Data Science\\\\Data science\\\\Opencv\\\\'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "942d9081",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread(path+'image1.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97b96d02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(636, 1024, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad9f3468",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1953792"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "efc99508",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1953792"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "636*1024*3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1cb86873",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image.item((635,1023,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "42b58e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('My_image', image)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "54144345",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 25,  98,  75],\n",
       "        [ 25,  98,  75],\n",
       "        [  0,   0, 255],\n",
       "        ...,\n",
       "        [199, 221, 233],\n",
       "        [200, 222, 234],\n",
       "        [200, 222, 234]],\n",
       "\n",
       "       [[ 25,  98,  75],\n",
       "        [ 25,  98,  75],\n",
       "        [ 25,  98,  75],\n",
       "        ...,\n",
       "        [197, 219, 231],\n",
       "        [197, 219, 231],\n",
       "        [197, 219, 231]],\n",
       "\n",
       "       [[ 25,  98,  75],\n",
       "        [ 25,  98,  75],\n",
       "        [ 25,  98,  75],\n",
       "        ...,\n",
       "        [194, 216, 228],\n",
       "        [194, 216, 228],\n",
       "        [194, 216, 228]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[  0,   0, 255],\n",
       "        [  0,   0, 255],\n",
       "        [ 77,  63,  64],\n",
       "        ...,\n",
       "        [  0,   0, 255],\n",
       "        [  0,   0, 255],\n",
       "        [123,  97,  91]],\n",
       "\n",
       "       [[  0,   0, 255],\n",
       "        [  0,   0, 255],\n",
       "        [ 78,  68,  68],\n",
       "        ...,\n",
       "        [  0,   0, 255],\n",
       "        [  0,   0, 255],\n",
       "        [  0,   0, 255]],\n",
       "\n",
       "       [[  0,   0, 255],\n",
       "        [  0,   0, 255],\n",
       "        [ 81,  76,  75],\n",
       "        ...,\n",
       "        [  0,   0, 255],\n",
       "        [  0,   0, 255],\n",
       "        [  0,   0, 255]]], dtype=uint8)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Drawing Line\n",
    "cv2.line(image,(0,318),(1000,318),(0,0,255),2)\n",
    "#pt are given as (x_coordinates,y_coordinates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4455c736",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 25,  98,  75],\n",
       "        [ 25,  98,  75],\n",
       "        [  0,   0, 255],\n",
       "        ...,\n",
       "        [199, 221, 233],\n",
       "        [200, 222, 234],\n",
       "        [200, 222, 234]],\n",
       "\n",
       "       [[ 25,  98,  75],\n",
       "        [ 25,  98,  75],\n",
       "        [ 25,  98,  75],\n",
       "        ...,\n",
       "        [197, 219, 231],\n",
       "        [197, 219, 231],\n",
       "        [197, 219, 231]],\n",
       "\n",
       "       [[ 25,  98,  75],\n",
       "        [ 25,  98,  75],\n",
       "        [ 25,  98,  75],\n",
       "        ...,\n",
       "        [194, 216, 228],\n",
       "        [194, 216, 228],\n",
       "        [194, 216, 228]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 79,  65,  66],\n",
       "        [ 77,  63,  64],\n",
       "        [ 77,  63,  64],\n",
       "        ...,\n",
       "        [  0,   0, 255],\n",
       "        [  0,   0, 255],\n",
       "        [123,  97,  91]],\n",
       "\n",
       "       [[ 82,  72,  72],\n",
       "        [ 81,  71,  71],\n",
       "        [ 78,  68,  68],\n",
       "        ...,\n",
       "        [  0,   0, 255],\n",
       "        [  0,   0, 255],\n",
       "        [  0,   0, 255]],\n",
       "\n",
       "       [[ 83,  78,  77],\n",
       "        [ 84,  79,  78],\n",
       "        [ 81,  76,  75],\n",
       "        ...,\n",
       "        [  0,   0, 255],\n",
       "        [  0,   0, 255],\n",
       "        [  0,   0, 255]]], dtype=uint8)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Draw Arrow\n",
    "cv2.arrowedLine(image,(0,0),(452,965),(25,98,75),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fed9e93f",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 25,  98,  75],\n",
       "        [ 25,  98,  75],\n",
       "        [  0,   0, 255],\n",
       "        ...,\n",
       "        [199, 221, 233],\n",
       "        [200, 222, 234],\n",
       "        [200, 222, 234]],\n",
       "\n",
       "       [[ 25,  98,  75],\n",
       "        [ 25,  98,  75],\n",
       "        [ 25,  98,  75],\n",
       "        ...,\n",
       "        [197, 219, 231],\n",
       "        [197, 219, 231],\n",
       "        [197, 219, 231]],\n",
       "\n",
       "       [[ 25,  98,  75],\n",
       "        [ 25,  98,  75],\n",
       "        [ 25,  98,  75],\n",
       "        ...,\n",
       "        [194, 216, 228],\n",
       "        [194, 216, 228],\n",
       "        [194, 216, 228]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 79,  65,  66],\n",
       "        [ 77,  63,  64],\n",
       "        [ 77,  63,  64],\n",
       "        ...,\n",
       "        [  0,   0, 255],\n",
       "        [  0,   0, 255],\n",
       "        [123,  97,  91]],\n",
       "\n",
       "       [[ 82,  72,  72],\n",
       "        [ 81,  71,  71],\n",
       "        [ 78,  68,  68],\n",
       "        ...,\n",
       "        [  0,   0, 255],\n",
       "        [  0,   0, 255],\n",
       "        [  0,   0, 255]],\n",
       "\n",
       "       [[ 83,  78,  77],\n",
       "        [ 84,  79,  78],\n",
       "        [ 81,  76,  75],\n",
       "        ...,\n",
       "        [  0,   0, 255],\n",
       "        [  0,   0, 255],\n",
       "        [  0,   0, 255]]], dtype=uint8)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Draw Rectangle\n",
    "cv2.rectangle(image,(25,63),(100,100),(145,98,63),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d49c1783",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 25,  98,  75],\n",
       "        [ 25,  98,  75],\n",
       "        [  0,   0, 255],\n",
       "        ...,\n",
       "        [199, 221, 233],\n",
       "        [200, 222, 234],\n",
       "        [200, 222, 234]],\n",
       "\n",
       "       [[ 25,  98,  75],\n",
       "        [ 25,  98,  75],\n",
       "        [ 25,  98,  75],\n",
       "        ...,\n",
       "        [197, 219, 231],\n",
       "        [197, 219, 231],\n",
       "        [197, 219, 231]],\n",
       "\n",
       "       [[ 25,  98,  75],\n",
       "        [ 25,  98,  75],\n",
       "        [ 25,  98,  75],\n",
       "        ...,\n",
       "        [194, 216, 228],\n",
       "        [194, 216, 228],\n",
       "        [194, 216, 228]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[  0,   0, 255],\n",
       "        [  0,   0, 255],\n",
       "        [ 77,  63,  64],\n",
       "        ...,\n",
       "        [  0,   0, 255],\n",
       "        [  0,   0, 255],\n",
       "        [123,  97,  91]],\n",
       "\n",
       "       [[  0,   0, 255],\n",
       "        [  0,   0, 255],\n",
       "        [ 78,  68,  68],\n",
       "        ...,\n",
       "        [  0,   0, 255],\n",
       "        [  0,   0, 255],\n",
       "        [  0,   0, 255]],\n",
       "\n",
       "       [[  0,   0, 255],\n",
       "        [  0,   0, 255],\n",
       "        [ 81,  76,  75],\n",
       "        ...,\n",
       "        [  0,   0, 255],\n",
       "        [  0,   0, 255],\n",
       "        [  0,   0, 255]]], dtype=uint8)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Draw Circle\n",
    "cv2.circle(image,(512,318),200,(0,25,69))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bcb068f0",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 26,  39,  53],\n",
       "        [ 15,  26,  40],\n",
       "        [  4,  13,  27],\n",
       "        ...,\n",
       "        [199, 221, 233],\n",
       "        [200, 222, 234],\n",
       "        [200, 222, 234]],\n",
       "\n",
       "       [[ 27,  38,  52],\n",
       "        [ 16,  27,  41],\n",
       "        [  8,  17,  31],\n",
       "        ...,\n",
       "        [197, 219, 231],\n",
       "        [197, 219, 231],\n",
       "        [197, 219, 231]],\n",
       "\n",
       "       [[ 25,  37,  49],\n",
       "        [ 20,  29,  43],\n",
       "        [ 15,  24,  38],\n",
       "        ...,\n",
       "        [194, 216, 228],\n",
       "        [194, 216, 228],\n",
       "        [194, 216, 228]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 79,  65,  66],\n",
       "        [ 77,  63,  64],\n",
       "        [ 77,  63,  64],\n",
       "        ...,\n",
       "        [123, 102, 100],\n",
       "        [121,  96,  92],\n",
       "        [123,  97,  91]],\n",
       "\n",
       "       [[ 82,  72,  72],\n",
       "        [ 81,  71,  71],\n",
       "        [ 78,  68,  68],\n",
       "        ...,\n",
       "        [124, 103, 101],\n",
       "        [126, 101,  97],\n",
       "        [134, 108, 102]],\n",
       "\n",
       "       [[ 83,  78,  77],\n",
       "        [ 84,  79,  78],\n",
       "        [ 81,  76,  75],\n",
       "        ...,\n",
       "        [123, 100,  98],\n",
       "        [124,  99,  95],\n",
       "        [133, 107, 101]]], dtype=uint8)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Put a text\n",
    "cv2.putText(image,\"Image\",(65,45),cv2.FONT_HERSHEY_PLAIN,0.6,(255,255,255),2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc96abac",
   "metadata": {},
   "source": [
    "#### Mouse Event Handling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce11e377",
   "metadata": {},
   "source": [
    "##### Putting text with mouse click"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8c8fb29a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def onmouse(event, x, y, flags, param):\n",
    "    if (event == cv2.EVENT_LBUTTONUP):\n",
    "        cv2.putText(image,\"Image\",(x,y),cv2.FONT_HERSHEY_PLAIN,2,(255,255,255),2)\n",
    "    if (event == cv2.EVENT_LBUTTONDBLCLK):\n",
    "        cv2.imwrite('C:\\\\Lachin\\\\Data Science\\\\Data science\\\\Opencv\\\\mouse.jpg',image)\n",
    "    cv2.imshow('frame', image)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "88c91491",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread(path+'image1.jpg')\n",
    "cv2.imshow('frame', image)\n",
    "cv2.setMouseCallback('frame', onmouse)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da807694",
   "metadata": {},
   "source": [
    "##### Drawing Shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c972deb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def onmouse(event, x, y, flags, param):\n",
    "    if (event == cv2.EVENT_LBUTTONUP):\n",
    "        points.append((x,y))\n",
    "        if(len(points)==2):\n",
    "            cv2.line(image,points[0],points[1],(0,0,255),2)\n",
    "    if (event == cv2.EVENT_MOUSEMOVE):\n",
    "        points.append((x,y))\n",
    "        if (len(points)>=2):\n",
    "            cv2.line(image,points[-2],points[-1],(56,255,100),2)\n",
    "    cv2.imshow('frame', image)\n",
    "    \n",
    "image = cv2.imread(path+'image1.jpg')\n",
    "points=[]\n",
    "cv2.imshow('frame', image)\n",
    "cv2.setMouseCallback('frame', onmouse)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n",
    "        \n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5468e0d",
   "metadata": {},
   "source": [
    "##### Calling for coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "23b8684d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def onmouse(event, x, y, flags, param):\n",
    "    if (event == cv2.EVENT_LBUTTONUP):\n",
    "        string1 = str(x)+\",\"+str(y)\n",
    "        cv2.putText(image,string1,(x,y),cv2.FONT_HERSHEY_PLAIN,2,(255,255,255),2)\n",
    "    if (event == cv2.EVENT_LBUTTONDBLCLK):\n",
    "        cv2.imwrite('C:\\\\Lachin\\\\Data Science\\\\Data science\\\\Opencv\\\\mouse.jpg',image)\n",
    "    cv2.imshow('frame', image)\n",
    "\n",
    "image = cv2.imread(path+'image1.jpg')\n",
    "cv2.imshow('frame', image)\n",
    "cv2.setMouseCallback('frame', onmouse)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea3eb974",
   "metadata": {},
   "source": [
    "##### Calling for color coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "245c1339",
   "metadata": {},
   "outputs": [],
   "source": [
    "def onmouse(event, x, y, flags, param):\n",
    "    if (event == cv2.EVENT_RBUTTONUP):\n",
    "        blue = str(image[y,x,0])\n",
    "        green = str(image[y,x,1])\n",
    "        red = str(image[y,x,2]) \n",
    "        cv2.putText(image,f\"{blue},{green},{red}\",(x,y),cv2.FONT_HERSHEY_PLAIN,2,(255,255,255),2)\n",
    "    cv2.imshow('frame', image)\n",
    "    \n",
    "image = cv2.imread(path+'image1.jpg')\n",
    "cv2.imshow('frame', image)\n",
    "cv2.setMouseCallback('frame', onmouse)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()          "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9b7e0ca",
   "metadata": {},
   "source": [
    "##### Color Picker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9e812f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def onmouse(event, x, y, flags, param):\n",
    "    if (event == cv2.EVENT_RBUTTONUP):\n",
    "        blue = str(image[y,x,0])\n",
    "        green = str(image[y,x,1])\n",
    "        red = str(image[y,x,2]) \n",
    "        cv2.putText(image,f\"{blue},{green},{red}\",(x,y),cv2.FONT_HERSHEY_PLAIN,2,(255,255,255),2)\n",
    "        image1 = np.zeros([512,512,3], np.uint8)\n",
    "        image1[:] = [blue,green,red]\n",
    "        cv2.imshow('frame1', image1)\n",
    "    cv2.imshow('frame', image)\n",
    "    \n",
    "image = cv2.imread(path+'image1.jpg')\n",
    "cv2.imshow('frame', image)\n",
    "cv2.setMouseCallback('frame', onmouse)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65f456fb",
   "metadata": {},
   "source": [
    "##### Cropping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "88864574",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(371, 57), (1007, 618)]\n"
     ]
    }
   ],
   "source": [
    "def onmouse(event, x, y, flags, param):\n",
    "    if (event == cv2.EVENT_LBUTTONUP):\n",
    "        points.append((x,y))\n",
    "        if(len(points)==2):\n",
    "            cv2.rectangle(image,points[0],points[1],(0,0,255),2)\n",
    "            print(points)\n",
    "            image1 = image[points[0][1]:points[1][1],points[0][0]:points[1][0]]\n",
    "            cv2.imshow('frame2', image1)\n",
    "    cv2.imshow('frame', image)\n",
    "    \n",
    "image = cv2.imread(path+'image1.jpg')\n",
    "points=[]\n",
    "cv2.imshow('frame', image)\n",
    "cv2.setMouseCallback('frame', onmouse)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c12bed65",
   "metadata": {},
   "source": [
    "#### Arithmetic Operations on Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "f88f1255",
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = cv2.imread('C:\\Lachin\\Data Science\\Data science\\Opencv\\image1.jpg')\n",
    "img2 = cv2.imread('C:\\Lachin\\Data Science\\Data science\\Opencv\\image2.jpg')\n",
    "img5 = np.ones(img1.shape, np.uint8)\n",
    "img5=img5*100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "5d8706fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "img3 = img1+100#All values are added by 100, if 255 exceeds, it will start again from 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "a0bc2dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "img4 =cv2.add(img1,100)#Only blue channel numbers are increased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "53d27ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "img6 = cv2.add(img1,img5)#Increse the brightness of the picture\n",
    "#if 255 is exceeded, it will not rewrite from the begining, it stops at 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "ee3c0599",
   "metadata": {},
   "outputs": [],
   "source": [
    "img2 = cv2.resize(img2, (img1.shape[1],img1.shape[0]))#resizing image 2 according to image 1\n",
    "img7 = cv2.add(img1,img2)#Two images on top together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "b5789834",
   "metadata": {},
   "outputs": [],
   "source": [
    "img8 = cv2.addWeighted(img2,0.7,img1,0.3,0)#Contro; the weights of the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "2554b63a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('frame1', img1)\n",
    "cv2.imshow('frame2', img2)\n",
    "cv2.imshow('frame3', img8)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc6ec25b",
   "metadata": {},
   "source": [
    "#### Bitwise Operations on Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "8c46ad64",
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = cv2.imread('C:\\Lachin\\Data Science\\Data science\\Opencv\\image1.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "6a4afa5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "im1 = np.zeros(img1.shape, np.uint8)\n",
    "im2 = np.zeros(img1.shape, np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "a2b5380b",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]]], dtype=uint8)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.rectangle(im1, (50,50),(300,300),(255,255,255),-1)\n",
    "cv2.circle(im1, (275,275),25,(255,255,255),-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "75ce728c",
   "metadata": {},
   "outputs": [],
   "source": [
    "im3 = cv2.bitwise_and(im1,im2)#Intersection area\n",
    "im4 = cv2.bitwise_or(im1,im2)#Both area\n",
    "im5 = cv2.bitwise_xor(im1,im2)\n",
    "im6 = cv2.bitwise_not(im1,im2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "1e95271e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('frame1', im1)\n",
    "cv2.imshow('frame2', im2)\n",
    "cv2.imshow('AND', im3)\n",
    "cv2.imshow('OR', im4)\n",
    "cv2.imshow('XOR', im5)\n",
    "cv2.imshow('NOT', im6)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "953b8900",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(636, 1024, 3)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "314f5e94",
   "metadata": {},
   "source": [
    "### Image Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0b692e1",
   "metadata": {},
   "source": [
    "#### 1. Image Translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "39e2f448",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('C:\\Lachin\\Data Science\\Data science\\Opencv\\image1.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f647189a",
   "metadata": {},
   "outputs": [],
   "source": [
    "row, col, chan = image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a6f099c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=40\n",
    "y=50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cca619d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "T = np.float64([[1,0,x],[0,1,y]])#This is the translation matrix which is used to translate the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8f9e5e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "image2 = cv2.warpAffine(image, T, (row,col))#image will be transalte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e045c1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('Frame1', image)\n",
    "cv2.imshow('frame2', image2)\n",
    "cv2.waitKey()#Time waiting for a keyboard argument\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6cd58a1",
   "metadata": {},
   "source": [
    "##### Creating an animation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "517611c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=0\n",
    "y=0\n",
    "\n",
    "while(True):\n",
    "    T = np.float64([[1,0,x],[0,1,y]])\n",
    "    image2 = cv2.warpAffine(image, T, (row,col))\n",
    "    cv2.imshow('Frame1', image)\n",
    "    cv2.imshow('frame2', image2)\n",
    "    k = cv2.waitKey(1)\n",
    "    if k==ord('q'):\n",
    "        break\n",
    "    x=x+0.1\n",
    "    y=y+0.1\n",
    "cv2.destroyAllWindows()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0296af34",
   "metadata": {},
   "source": [
    "#### 2. Rotation of Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a4bcfd5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('C:\\Lachin\\Data Science\\Data science\\Opencv\\img1.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "75a2bebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "row, col, chan = image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a9120d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "R = cv2.getRotationMatrix2D((row/2,col/2), 45,0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5687c763",
   "metadata": {},
   "outputs": [],
   "source": [
    "image2 = cv2.warpAffine(image, R, (row,col))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b7d3b7aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('Frame1', image)\n",
    "cv2.imshow('frame2', image2)\n",
    "cv2.waitKey()#Time waiting for a keyboard argument\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9533e30c",
   "metadata": {},
   "source": [
    "##### Animation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a87523b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "angle = 0\n",
    "\n",
    "while(True):\n",
    "    if angle == 360:\n",
    "        angle = 0\n",
    "    R = cv2.getRotationMatrix2D((row/2,col/2), angle,0.5)\n",
    "    image2 = cv2.warpAffine(image, R, (row,col))\n",
    "    cv2.imshow('Frame1', image)\n",
    "    cv2.imshow('frame2', image2)\n",
    "    k = cv2.waitKey(1)\n",
    "    if k==ord('q'):\n",
    "        break\n",
    "    angle+=0.1\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a91b8b7",
   "metadata": {},
   "source": [
    "### Scaling of Images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0774a74",
   "metadata": {},
   "source": [
    "##### Interpolation Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "54a73d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('C:\\Lachin\\Data Science\\Data science\\Opencv\\img1.png')\n",
    "cv2.imshow('Image', image)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1d889f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "image2 = cv2.resize(image, dsize = (675,675), interpolation = cv2.INTER_AREA)\n",
    "cv2.imshow('AREA', image2)\n",
    "image2 = cv2.resize(image, dsize = None, fx=0.5 ,fy=0.5, interpolation = cv2.INTER_LINEAR)\n",
    "cv2.imshow('LINEAR', image2)\n",
    "image2 = cv2.resize(image, dsize = None, fx=0.5 ,fy=0.5, interpolation = cv2.INTER_CUBIC)\n",
    "cv2.imshow('CUBIC', image2)\n",
    "image2 = cv2.resize(image, dsize = None, fx=0.5 ,fy=0.5, interpolation = cv2.INTER_LANCZOS4)\n",
    "cv2.imshow('LANCZOS', image2)\n",
    "image2 = cv2.resize(image, dsize = None, fx=0.5 ,fy=0.5, interpolation = cv2.INTER_LINEAR_EXACT)\n",
    "cv2.imshow('LINEAR_EXACT', image2)\n",
    "image2 = cv2.resize(image, dsize = None, fx=0.5 ,fy=0.5, interpolation = cv2.INTER_NEAREST)\n",
    "cv2.imshow('NEAREST', image2)\n",
    "cv2.imshow('Image', image)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n",
    "#For enlarging most of the time, LANCOS is giving perfect imag\n",
    "#For downsizing area gives the best one\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c89a0c3a",
   "metadata": {},
   "source": [
    "##### Pyramid Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "710fef36",
   "metadata": {},
   "outputs": [],
   "source": [
    "image2 = cv2.pyrDown(image)\n",
    "image3 = cv2.pyrUp(image)\n",
    "cv2.imshow('pyrdown', image2)\n",
    "cv2.imshow('pyup', image3)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da29ab69",
   "metadata": {},
   "source": [
    "### Bluring and Smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3474001a",
   "metadata": {},
   "outputs": [],
   "source": [
    "image1 = cv2.imread('C:\\Lachin\\Data Science\\Data science\\Opencv\\img1.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "49b36692",
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_5x5 = (np.ones((5,5), np.uint8))/25\n",
    "kernel_9x9 = (np.ones((9,9), np.uint8))/25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a4ed2fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "image2 = cv2.filter2D(image1,-1, kernel_5x5)#Runs the filter matrix on the image matrix\n",
    "image3 = cv2.filter2D(image1,-1, kernel_9x9)\n",
    "cv2.imshow('Orgignal', image1)\n",
    "cv2.imshow('Filter2d 5x5', image2)\n",
    "cv2.imshow('filter 9x9', image3)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5faa821a",
   "metadata": {},
   "outputs": [],
   "source": [
    "image4 = cv2.blur(image1,(5,5))\n",
    "image5 = cv2.GaussianBlur(image1, (5,5), 0)\n",
    "image6 = cv2.medianBlur(image1,5)\n",
    "image7 = cv2.bilateralFilter(image1,9,75,75)#preserve edges and blur the image(more beneficial)\n",
    "cv2.imshow('Orgignal', image1)\n",
    "cv2.imshow('BLUR', image4)\n",
    "cv2.imshow('GAUSSIAN BLUR', image5)\n",
    "cv2.imshow('MEDIAN BLUR', image6)\n",
    "cv2.imshow('BI LATERAL FILTER', image7)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2de9c414",
   "metadata": {},
   "source": [
    "### Image Sharpening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3a48afd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Opposite of bluring\n",
    "#this will sharpen the edges of the object\n",
    "image1 = cv2.imread('C:\\Lachin\\Data Science\\Data science\\Opencv\\img1.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "63cad72d",
   "metadata": {},
   "outputs": [],
   "source": [
    "kernal = np.array([[-1,-1,-1],[-1,9,-1],[-1,-1,-1]])\n",
    "kernal1 = np.array([[-1,-1,-1,-1,-1],\n",
    "                    [-1,-1,-1,-1,-1],\n",
    "                    [-1,-1,25,-1,-1],\n",
    "                    [-1,-1,-1,-1,-1],\n",
    "                    [-1,-1,-1,-1,-1]])#Edges are more visible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f8fa0e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "image2 = cv2.filter2D(image1,-1, kernal1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bc3b1752",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('Orginal', image1)\n",
    "cv2.imshow('Sharpened_Image', image2)#Edges are more visible\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d736bdd8",
   "metadata": {},
   "source": [
    "# Computer Vision Techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba5c3ad9",
   "metadata": {},
   "source": [
    "### Simple Thresholding(Global Thresholding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4f845b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To identify the darker and the light areas of the picture\n",
    "#Most of the time, best to work with the black and white images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "90bd7415",
   "metadata": {},
   "outputs": [],
   "source": [
    "image1 = cv2.imread('C:\\Lachin\\Data Science\\Data science\\Opencv\\img1.png')\n",
    "image1 = cv2.cvtColor(image1, cv2.COLOR_BGR2GRAY)\n",
    "cv2.imshow('Orgignal', image1)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "24e9fab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ret, image2 = cv2.threshold(image1, 140 , 225, cv2.THRESH_BINARY)\n",
    "#Covert all pixels below 140(threshhold value) to 0\n",
    "#convert all pixels above threshold to 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "06be145b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ret, image3 = cv2.threshold(image1, 140, 225, cv2.THRESH_BINARY_INV)\n",
    "#convert all pixels below 140 to 255\n",
    "#covert all pixels above 140 to 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a71e671f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ret, image4 = cv2.threshold(image1, 140, 225, cv2.THRESH_TRUNC)\n",
    "#convert all above pixels which are above threshold to 140\n",
    "#pixels below threshold value remain the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9735316c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ret, image5 = cv2.threshold(image1, 140, 225, cv2.THRESH_TOZERO)\n",
    "#whatever above threshold value, remain the same\n",
    "#pixels below threshold value, become 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "14ac0ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ret, image6 = cv2.threshold(image1, 140, 225, cv2.THRESH_TOZERO_INV)\n",
    "#Pixels above threshold value, become 0\n",
    "#pixels below threshold value remain the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "61a6674a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('Orgignal', image1)\n",
    "cv2.imshow('Binary', image2)\n",
    "cv2.imshow('Binary_Inv', image3)\n",
    "cv2.imshow('Trunc', image4)\n",
    "cv2.imshow('Tozero', image5)\n",
    "cv2.imshow('Tozero_Inv', image6)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a6d51e",
   "metadata": {},
   "source": [
    "### Adaptive Thresholding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a872f786",
   "metadata": {},
   "outputs": [],
   "source": [
    "image1 = cv2.imread('C:\\Lachin\\Data Science\\Data science\\Opencv\\img2.jpg')\n",
    "image1 = cv2.cvtColor(image1, cv2.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "da915733",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('AT', image1)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "998b59d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "image2 = cv2.adaptiveThreshold(image1, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 7, 5)\n",
    "#blocksize must be odd and greater than 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0123b87d",
   "metadata": {},
   "outputs": [],
   "source": [
    "image3 = cv2.adaptiveThreshold(image1, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 7,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3c8f565e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('Original', image1)\n",
    "cv2.imshow('Mean', image2)\n",
    "cv2.imshow('Gaussian', image3)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb35ff63",
   "metadata": {},
   "source": [
    "### Erotion & Dialation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "aa51fc62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Want good edges ----> Dialation\n",
    "# Thinning out the edges -------> Erotion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7ffd6931",
   "metadata": {},
   "outputs": [],
   "source": [
    "image1 = cv2.imread('C:\\Lachin\\Data Science\\Data science\\Opencv\\img3.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "24d46f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "kernal = np.ones((5,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5e4e531c",
   "metadata": {},
   "outputs": [],
   "source": [
    "image2 = cv2.erode(image1,kernal, iterations=1)\n",
    "image3 = cv2.dilate(image1, kernal, iterations=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "50ec204f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('Orgignal', image1)\n",
    "cv2.imshow('Erotion', image2)\n",
    "cv2.imshow('Dialation', image3)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "552fcfda",
   "metadata": {},
   "outputs": [],
   "source": [
    "image4 = cv2.morphologyEx(image1, cv2.MORPH_OPEN, kernal)\n",
    "image5 = cv2.morphologyEx(image1, cv2.MORPH_CLOSE, kernal)\n",
    "# Opening ----> first do the erotion and then dialation\n",
    "# Closing ----> first do the dialtion and then erotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0ce1bb89",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('Orgignal', image1)\n",
    "cv2.imshow('Open', image4)\n",
    "cv2.imshow('Close', image5)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a56ca37",
   "metadata": {},
   "source": [
    "### Edge Detection (Canny)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ed8fde0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "image1 = cv2.imread('C:\\Lachin\\Data Science\\Data science\\Opencv\\img1.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0c052114",
   "metadata": {},
   "outputs": [],
   "source": [
    "image2 = cv2.Canny(image1, 30,100)\n",
    "#when threshold 2 is increasing, edges will be missed\n",
    "#When it is decreasing, edges will be identified better(,ore edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d6e5fda0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('Original', image1)\n",
    "cv2.imshow('Edge_Detection', image2)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee1ed3b0",
   "metadata": {},
   "source": [
    "### Image Pyramids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13ed9b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import cv2 as cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc6322a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "image1 = cv2.imread('C:\\Lachin\\Data Science\\Data science\\Opencv\\img1.png')\n",
    "# image2 = cv2.pyrDown(image1)\n",
    "# image3 = cv2.pyrUp(image1)\n",
    "# cv2.imshow('Original', image1)\n",
    "# cv2.imshow('Down', image2)\n",
    "# cv2.imshow('Up', image3)\n",
    "# cv2.waitKey()\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9df0c553",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian(image):\n",
    "    gp = []\n",
    "    gp.append(image)\n",
    "    for i in range(6):\n",
    "        image = cv2.pyrDown(image)\n",
    "        gp.append(image)\n",
    "        cv2.imshow(str(i), gp[i])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0b0f92a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def laplacian(image):\n",
    "    gp = [image]\n",
    "    for i in range(6):\n",
    "        image = cv2.pyrDown(image)\n",
    "        gp.append(image)\n",
    "    lp = [gp[5]]\n",
    "    for i in range(5,0,-1):\n",
    "        gauss_expand = cv2.pyrUp(gp[i])\n",
    "        lap = cv2.subtract(gp[i-1], gauss_expand)\n",
    "        lp.append(lap)\n",
    "    return lp\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8a43ee7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "gaussian(image1)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "685fcb61",
   "metadata": {},
   "source": [
    "### Contours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0dd03016",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_image = cv2.imread('C:\\Lachin\\Data Science\\Data science\\Opencv\\opencv2.png')\n",
    "image = cv2.cvtColor(original_image, cv2.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d3896a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "RET, image1 = cv2.threshold(image,170,225,0)\n",
    "image1 = cv2.Canny(image,30,50)# Canny is detetciong most of the edges here, withoout it number of contours will be reduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "17a95d52",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 25, 255, 156],\n",
       "        [ 25, 255, 156],\n",
       "        [ 25, 255, 156],\n",
       "        ...,\n",
       "        [ 25, 255, 156],\n",
       "        [ 25, 255, 156],\n",
       "        [ 25, 255, 156]],\n",
       "\n",
       "       [[ 25, 255, 156],\n",
       "        [ 25, 255, 156],\n",
       "        [ 25, 255, 156],\n",
       "        ...,\n",
       "        [ 25, 255, 156],\n",
       "        [ 25, 255, 156],\n",
       "        [ 25, 255, 156]],\n",
       "\n",
       "       [[ 25, 255, 156],\n",
       "        [ 25, 255, 156],\n",
       "        [ 25, 255, 156],\n",
       "        ...,\n",
       "        [ 25, 255, 156],\n",
       "        [ 25, 255, 156],\n",
       "        [ 25, 255, 156]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 25, 255, 156],\n",
       "        [ 25, 255, 156],\n",
       "        [ 25, 255, 156],\n",
       "        ...,\n",
       "        [ 25, 255, 156],\n",
       "        [ 25, 255, 156],\n",
       "        [ 25, 255, 156]],\n",
       "\n",
       "       [[ 25, 255, 156],\n",
       "        [ 25, 255, 156],\n",
       "        [ 25, 255, 156],\n",
       "        ...,\n",
       "        [ 25, 255, 156],\n",
       "        [ 25, 255, 156],\n",
       "        [ 25, 255, 156]],\n",
       "\n",
       "       [[ 25, 255, 156],\n",
       "        [ 25, 255, 156],\n",
       "        [ 25, 255, 156],\n",
       "        ...,\n",
       "        [ 25, 255, 156],\n",
       "        [ 25, 255, 156],\n",
       "        [ 25, 255, 156]]], dtype=uint8)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contours, hierarchy = cv2.findContours(image1, cv2.RETR_LIST, cv2.CHAIN_APPROX_NONE)\n",
    "#CHAIN_APPROX_SIMPLE is better for shapes,it doesn't give all the values\n",
    "cv2.drawContours(original_image, contours, -1, (25,255,156), 3)\n",
    "#-1 for all the contours, otherwise the index of the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a4eba8ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('Original_Image', original_image)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47fe482d",
   "metadata": {},
   "source": [
    "##### Detetcting only the Red contour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fc0cb3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_image = cv2.imread('C:\\Lachin\\Data Science\\Data science\\Opencv\\opencv2.png')\n",
    "image = cv2.cvtColor(original_image, cv2.COLOR_BGR2HSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "bb42c2dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = np.array((0,70,70))\n",
    "ur = np.array((10,255,255))\n",
    "mask1 = cv2.inRange(image,lr, ur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7a8d6eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = np.array((170,70,70))\n",
    "ur = np.array((180,255,255))\n",
    "mask2 = cv2.inRange(image,lr,ur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4ac3bc2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = mask1 + mask2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "78df65f9",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        ...,\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255]],\n",
       "\n",
       "       [[255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        ...,\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255]],\n",
       "\n",
       "       [[255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        ...,\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        ...,\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255]],\n",
       "\n",
       "       [[255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        ...,\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255]],\n",
       "\n",
       "       [[255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        ...,\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255]]], dtype=uint8)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contours, hierarchy = cv2.findContours(mask, cv2.RETR_LIST, cv2.CHAIN_APPROX_NONE)\n",
    "#CHAIN_APPROX_SIMPLE is better for shapes,it doesn't give all the values\n",
    "cv2.drawContours(original_image, contours, -1, (25,255,156), 3)\n",
    "#-1 for all the contours, otherwise the index of the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "683b7ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('Original_Image', original_image)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9579b3ee",
   "metadata": {},
   "source": [
    "##### Sorting contours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5e100c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "kernal = np.ones((512,512,3), np.uint8)\n",
    "kernal=kernal*255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c52ab0d3",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        ...,\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255]],\n",
       "\n",
       "       [[255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        ...,\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255]],\n",
       "\n",
       "       [[255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        ...,\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        ...,\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255]],\n",
       "\n",
       "       [[255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        ...,\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255]],\n",
       "\n",
       "       [[255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        ...,\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255]]], dtype=uint8)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.rectangle(kernal, (50,50),(150,150),(0,0,0),-1)\n",
    "cv2.circle(kernal, (100,250),90,(0,0,0),-1)\n",
    "cv2.ellipse(kernal,(350,300),(150,200),0,0,360,(0,0,0),-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "71cd0cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('shapes', kernal)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ff931cea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imwrite('C:\\Lachin\\Data Science\\Data science\\Opencv\\shapes.png', kernal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "401633c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Sorting Starts now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01e1323c",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_image = cv2.imread('C:\\Lachin\\Data Science\\Data science\\Opencv\\shapes.png')\n",
    "cv2.imshow('Shapes', original_image)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "43be7e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.cvtColor(original_image, cv2.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "81a9558a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ret, image = cv2.threshold(image,70,255,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "66bf7146",
   "metadata": {},
   "outputs": [],
   "source": [
    "contours, hierarchy = cv2.findContours(image, cv2.RETR_LIST, cv2.CHAIN_APPROX_NONE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "939ee99a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_contours = sorted(contours, key=cv2.contourArea, reverse=True)[1:]\n",
    "#Because the 0th index contour is the whole white background image contour\n",
    "#IF reverse False, indexing must be [:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7c0d6c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, cnt in enumerate(sorted_contours):\n",
    "    m = cv2.moments(cnt)\n",
    "    if m[\"m00\"] !=0:\n",
    "        cx = int(m[\"m10\"]/m[\"m00\"])\n",
    "        cy = int(m[\"m01\"]/m[\"m00\"])\n",
    "    else:\n",
    "        cx=0\n",
    "        cy=0\n",
    "    \n",
    "    cv2.drawContours(original_image, [cnt], -1, (200,100,0),3)\n",
    "    cv2.putText(original_image, str(i+1), (cx,cy), cv2.FONT_HERSHEY_COMPLEX, 1 ,(255,200,0),1)\n",
    "    cv2.imshow('Original', original_image)\n",
    "    cv2.waitKey()\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b12030",
   "metadata": {},
   "source": [
    "##### Matching contours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "56ffa039",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        ...,\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255]],\n",
       "\n",
       "       [[255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        ...,\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255]],\n",
       "\n",
       "       [[255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        ...,\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        ...,\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255]],\n",
       "\n",
       "       [[255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        ...,\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255]],\n",
       "\n",
       "       [[255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        ...,\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255]]], dtype=uint8)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kernal2 = np.ones((512,512,3), np.uint8)\n",
    "kernal2=kernal2*255\n",
    "cv2.circle(kernal2, (256,256),100,(0,0,0),-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b218c288",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv2.imshow('circle', kernal)\n",
    "# cv2.waitKey()\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e58fb3a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imwrite('C:\\\\Lachin\\\\Data Science\\\\Data science\\\\Opencv\\\\template1.jpg', kernal2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "500089b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Start of matching part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4cc9162c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import cv2 as cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0992f2c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_image = cv2.imread('C:\\\\Lachin\\\\Data Science\\\\Data science\\\\Opencv\\\\shapes.png')\n",
    "template = cv2.imread('C:\\\\Lachin\\\\Data Science\\\\Data science\\\\Opencv\\\\template1.jpg')\n",
    "cv2.imshow('Original', original_image)\n",
    "cv2.imshow('template', template)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e18f786b",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.cvtColor(original_image, cv2.COLOR_BGR2GRAY)\n",
    "image1 = cv2.cvtColor(template, cv2.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cfc5d4fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "RET, image = cv2.threshold(image,170,225,0)\n",
    "RET, image1 = cv2.threshold(image,170,225,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4fc0922c",
   "metadata": {},
   "outputs": [],
   "source": [
    "contours, hierarchy = cv2.findContours(image1, cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)\n",
    "sorted_contours = sorted(contours, key=cv2.contourArea, reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ab092131",
   "metadata": {},
   "outputs": [],
   "source": [
    "template_contours = sorted_contours[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cd948e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "contours, hierarchy = cv2.findContours(image, cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)\n",
    "sorted_contours = sorted(contours, key=cv2.contourArea, reverse=True)[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ca131a00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.02789337885795029\n",
      "0.004204643287673893\n"
     ]
    }
   ],
   "source": [
    "smatch=10\n",
    "for c in sorted_contours:\n",
    "    match = cv2.matchShapes(template_contours,c,1,0.0)\n",
    "    print(match)\n",
    "    if match < smatch:\n",
    "        cnt=c\n",
    "        smatch = match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "76698c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.drawContours(original_image, cnt, -1, (200,100,0),3)\n",
    "cv2.imshow('Original', original_image)\n",
    "cv2.imshow('template', template)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d9e3fa4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
